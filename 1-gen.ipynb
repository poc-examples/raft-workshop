{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP Gorilla Raft Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./setup_raft.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install dotenv pandas mdc openai datasets transformers PyPDF2 langchain_experimental langchain_openai azure-identity coloredlogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LOAD SETTINGS\n",
    "load_dotenv(\"config.env\")\n",
    "\n",
    "print(f\"Using multi-model: {os.getenv('OPENAI_BASE_URL')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ds_name = \"surfing\"\n",
    "format = \"chat\"\n",
    "\n",
    "os.environ[\"DOC_PATH\"] = \"sample_data/surfing/Surfing-Wikipedia.pdf\"\n",
    "\n",
    "finetuning_train_split = .8\n",
    "finetuning_valid_split = .1\n",
    "finetuning_threshold = 65\n",
    "raft_questions = 2\n",
    "\n",
    "print(\"Training Document Path:\", os.getenv(\"DOC_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# MAP DATASET LOCATION\n",
    "ds_path = f\"dataset/{ds_name}\"\n",
    "ds_output_file = f\"{ds_path}.jsonl\"\n",
    "\n",
    "os.environ[\"DATASET_OUTPUT_PATH\"] = ds_path\n",
    "\n",
    "print(\"Dataset name:\", ds_name)\n",
    "print(\"Dataset path:\", ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "qa_threshold = ceil(finetuning_threshold / finetuning_train_split)\n",
    "\n",
    "print(f\"QA threshold: {qa_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 .gorilla/raft/raft.py \\\n",
    "    --datapath $DOC_PATH \\\n",
    "    --output $DATASET_OUTPUT_PATH \\\n",
    "    --doctype pdf \\\n",
    "    --chunk_size 512 \\\n",
    "    --questions 2 \\\n",
    "    --distractors 3 \\\n",
    "    --embedding_model $EMBEDDING_MODEL_ID \\\n",
    "    --completion_model $TEACHER_MODEL_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raft_arrow_file = f\"{ds_path}/data-00000-of-00001.arrow\"\n",
    "os.environ[\"RAFT_ARROW_FILE\"] = raft_arrow_file\n",
    "\n",
    "dataset_path = f\"{ds_path}-files/{ds_name}-full.jsonl\"\n",
    "dataset_path_hf = f\"{ds_path}-files/{ds_name}-hf.full.jsonl\"\n",
    "os.environ[\"DATASET_PATH_HF\"] = dataset_path_hf\n",
    "\n",
    "dataset_path_hf_train = f\"{ds_path}-files/{ds_name}-hf.train.jsonl\"\n",
    "dataset_path_hf_valid = f\"{ds_path}-files/{ds_name}-hf.valid.jsonl\"\n",
    "dataset_path_hf_eval = f\"{ds_path}-files/{ds_name}-hf.eval.jsonl\"\n",
    "\n",
    "dataset_path_ft_train = f\"{ds_path}-files/{ds_name}-ft.train.jsonl\"\n",
    "dataset_path_ft_valid = f\"{ds_path}-files/{ds_name}-ft.valid.jsonl\"\n",
    "\n",
    "print(f\"Reading arrow file {raft_arrow_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python .gorilla/raft/format.py \\\n",
    "    --input $RAFT_ARROW_FILE \\\n",
    "    --output $DATASET_PATH_HF \\\n",
    "    --output-format hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_full_df = pd.read_json(dataset_path_hf, lines=True)\n",
    "hf_full_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from random import randint\n",
    "\n",
    "sample_idx = 2#randint(0, len(hf_full_df) - 1)\n",
    "sample = hf_full_df.iloc[sample_idx]\n",
    "instruction_md = sample.instruction.replace(\"<DOCUMENT>\", \"`<DOCUMENT>`\").replace(\"</DOCUMENT>\", \"`</DOCUMENT>`\")\n",
    "oracle_context_md = sample.oracle_context.replace(\"<DOCUMENT>\", \"`<DOCUMENT>`\").replace(\"</DOCUMENT>\", \"`</DOCUMENT>`\")\n",
    "sample_answer_md = sample.cot_answer.replace(\"<ANSWER>\", \"`<ANSWER>`\").replace(\"##begin_quote##\", \"`##begin_quote##`\").replace(\"##end_quote##\", \"`##end_quote##`\")\n",
    "display(Markdown(f\"\"\"\n",
    "## Oracle Context\n",
    "{oracle_context_md}\n",
    "\n",
    "## Question\n",
    "{sample.question}\n",
    "\n",
    "## CoT Answer\n",
    "{sample_answer_md}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into 80%/10%/10%\n",
    "import numpy as np\n",
    "\n",
    "samples_count = len(hf_full_df)\n",
    "splits = [int(finetuning_train_split * samples_count), int((finetuning_train_split + finetuning_valid_split) * samples_count)]\n",
    "print(f\"Splitting dataset at {splits}\")\n",
    "hf_train_df, hf_valid_df, hf_eval_df = np.split(hf_full_df, splits)\n",
    "hf_train_df.to_json(dataset_path_hf_train, orient=\"records\", lines=True)\n",
    "hf_valid_df.to_json(dataset_path_hf_valid, orient=\"records\", lines=True)\n",
    "hf_eval_df.to_json(dataset_path_hf_eval, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python .gorilla/raft/format.py \\\n",
    "    --input $dataset_path_hf_train \\\n",
    "    --input-type jsonl \\\n",
    "    --output $dataset_path_ft_train \\\n",
    "    --output-format $format \\\n",
    "    --output-completion-prompt-column text\\\n",
    "    --output-completion-completion-column ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python .gorilla/raft/format.py \\\n",
    "    --input $dataset_path_hf_valid \\\n",
    "    --input-type jsonl \\\n",
    "    --output $dataset_path_ft_valid \\\n",
    "    --output-format $format \\\n",
    "    --output-completion-prompt-column text\\\n",
    "    --output-completion-completion-column ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_ft_valid_df = pd.read_json(dataset_path_ft_valid, lines=True)\n",
    "dataset_path_ft_valid_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json(dataset_path_hf_eval, lines=True).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
