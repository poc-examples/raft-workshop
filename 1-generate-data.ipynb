{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gorilla RAFT setup section\n",
    "\n",
    "This cell is just a section header comment that marks the start of the Gorilla RAFT setup steps used to generate synthetic training data.\n",
    "This will execute the `setup_raft.sh` helper script, which prepares the Gorilla RAFT environment (e.g., cloning the RAFT repo, installing its dependencies, and setting up any required directories or configuration files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./setup_raft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python dependencies for the workshop\n",
    "\n",
    "This cell installs all Python packages required for the data generation pipeline, including environment management (`dotenv`), data handling (`pandas`, `datasets`), model tooling (`openai`, `transformers`, LangChain libraries), Azure identity helpers(not used dependency of gorilla raft), logging (`coloredlogs`), and any RAFT-related utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install dotenv pandas mdc openai datasets transformers PyPDF2 langchain_experimental langchain_openai azure-identity coloredlogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration and define dataset settings\n",
    "\n",
    "This cell sets up the basic experiment parameters:\n",
    "\n",
    "- Loads environment variables (dataset name, paths, models).\n",
    "- Defines how much data goes to training vs. validation.(splits)\n",
    "- Sets a QA limit so RAFT doesn’t generate too many questions per document.\n",
    "- Prints a summary so you can confirm all settings before generating data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from math import ceil\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# LOAD CONFIGURATION\n",
    "# ---------------------------------------------------------------------\n",
    "load_dotenv(\"config.env\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# DATASET CONFIGURATION\n",
    "# ---------------------------------------------------------------------\n",
    "ds_name = os.getenv(\"DATASET_NAME\")\n",
    "ds_file = os.getenv(\"DATASET_FILE\")\n",
    "os.environ[\"DATAFILE_PATH\"] = f\"sample_data/{ds_name}/{ds_file}\"\n",
    "os.environ[\"FORMAT\"] = \"chat\"\n",
    "\n",
    "# Define dataset output paths\n",
    "ds_path = f\"dataset/{ds_name}\"\n",
    "os.environ[\"DATASET_OUTPUT_PATH\"] = ds_path\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# TRAINING PARAMETERS\n",
    "# ---------------------------------------------------------------------\n",
    "finetuning_train_split = 0.8\n",
    "finetuning_valid_split = 0.1\n",
    "finetuning_threshold = 65\n",
    "raft_questions = 2\n",
    "qa_threshold = ceil(finetuning_threshold / finetuning_train_split)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# PRINT CONFIGURATION SUMMARY\n",
    "# ---------------------------------------------------------------------\n",
    "print(\n",
    "    f\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════\n",
    "    RAFT Synthetic Dataset Generation - Configuration Overview\n",
    "═══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "MODEL & ROUTER\n",
    "──────────────────────────────────────────────\n",
    " Multi-Model Router URL  : {os.getenv('OPENAI_BASE_URL')}\n",
    " Teacher Model           : {os.getenv('TEACHER_MODEL_ID')}\n",
    " Embedding Model         : {os.getenv('EMBEDDING_MODEL_ID')}\n",
    "\n",
    "DATASET SETUP\n",
    "──────────────────────────────────────────────\n",
    " Dataset Name            : {ds_name}\n",
    " Dataset File            : {ds_file}\n",
    " Training Document Path  : {os.getenv('DATAFILE_PATH')}\n",
    " Output Dataset Path     : {ds_path}\n",
    "\n",
    "TRAINING PARAMETERS\n",
    "──────────────────────────────────────────────\n",
    " Finetuning Train Split  : {finetuning_train_split}\n",
    " Finetuning Valid Split  : {finetuning_valid_split}\n",
    " Finetuning Threshold    : {finetuning_threshold}\n",
    " QA Threshold (derived)  : {qa_threshold}\n",
    " Questions per Chunk     : {raft_questions}\n",
    "\n",
    "═══════════════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gorilla RAFT to generate synthetic QA data\n",
    "\n",
    "This cell invokes the Gorilla RAFT CLI (`raft.py`) to:\n",
    "- Ingest the source document(s) from `$DATAFILE_PATH` (PDF),\n",
    "- Chunk the document into 512-token segments,\n",
    "- Generate 2 questions per chunk, including **distractors** (plausible but incorrect answer choices),\n",
    "- Use the specified embedding and completion models.\n",
    "\n",
    "The output is written to `$DATASET_OUTPUT_PATH` as an **Arrow file** (a columnar data format that’s efficient for large datasets) that will be used in later steps.\n",
    "\n",
    ">Why include distractors?\n",
    ">Distractors are intentionally wrong but believable answers. They help the model learn to distinguish correct information from similar false options improving >comprehension and reasoning rather than simple memorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 .gorilla/raft/raft.py \\\n",
    "    --datapath \"$DATAFILE_PATH\" \\\n",
    "    --output \"$DATASET_OUTPUT_PATH\" \\\n",
    "    --doctype pdf \\\n",
    "    --chunk_size 512 \\\n",
    "    --questions 2 \\\n",
    "    --distractors 3 \\\n",
    "    --embedding_model \"$EMBEDDING_MODEL_ID\" \\\n",
    "    --completion_model \"$TEACHER_MODEL_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define intermediate dataset file paths and summarize them\n",
    "\n",
    "This cell:\n",
    "- Records the main RAFT Arrow file path and exports it as `RAFT_ARROW_FILE`,\n",
    "- Builds paths for the intermediate HF-style JSONL files (full, train, valid, eval),\n",
    "- Builds paths for the final finetuning JSONL files (train and valid),\n",
    "- Stores all of these paths in environment variables.(passed to raft cli)\n",
    "- Prints a summary of the intermediate and final dataset file locations for quick reference.\n",
    "\n",
    "#### HF style JSONL files\n",
    ">A Hugging Face (HF) style JSONL file stores one training example per line in plain text.\n",
    ">Each line is a small JSON object containing fields like \"instruction\", \"input\", and \"output\".\n",
    ">This makes it easy to preview, edit, and load datasets with the Hugging Face datasets library or similar tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raft_arrow_file = f\"{ds_path}/data-00000-of-00001.arrow\"\n",
    "os.environ[\"RAFT_ARROW_FILE\"] = raft_arrow_file\n",
    "\n",
    "dataset_path_hf = f\"{ds_path}-files/{ds_name}-hf.full.jsonl\"\n",
    "os.environ[\"DATASET_PATH_HF\"] = dataset_path_hf\n",
    "\n",
    "dataset_path_hf_train = f\"{ds_path}-files/{ds_name}-hf.train.jsonl\"\n",
    "os.environ[\"DATASET_PATH_HF_TRAIN\"] = dataset_path_hf_train\n",
    "dataset_path_hf_valid = f\"{ds_path}-files/{ds_name}-hf.valid.jsonl\"\n",
    "os.environ[\"DATASET_PATH_HF_VALID\"] = dataset_path_hf_valid\n",
    "dataset_path_hf_eval  = f\"{ds_path}-files/{ds_name}-hf.eval.jsonl\"\n",
    "\n",
    "dataset_path_ft_train = f\"{ds_path}-files/{ds_name}-ft.train.jsonl\"\n",
    "os.environ[\"DATASET_PATH_FT_TRAIN\"] = dataset_path_ft_train\n",
    "dataset_path_ft_valid = f\"{ds_path}-files/{ds_name}-ft.valid.jsonl\"\n",
    "os.environ[\"DATASET_PATH_FT_VALID\"] = dataset_path_ft_valid\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "Intermediate Dataset Files\n",
    "--------------------------\n",
    "RAFT arrow file        : {raft_arrow_file}\n",
    "\n",
    "HF JSONL (synthetic data)\n",
    "  Full dataset         : {dataset_path_hf}\n",
    "  Train split          : {dataset_path_hf_train}\n",
    "  Valid split          : {dataset_path_hf_valid}\n",
    "  Eval split           : {dataset_path_hf_eval}\n",
    "\n",
    "Finetuning JSONL (final RAFT-style)\n",
    "  Train split          : {dataset_path_ft_train}\n",
    "  Valid split          : {dataset_path_ft_valid}\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert RAFT Arrow dataset to HF JSONL format\n",
    "\n",
    "This cell uses the RAFT `format.py` helper to convert the Arrow file (`$RAFT_ARROW_FILE`) into a Hugging Face–style JSONL file at `$DATASET_PATH_HF`.  \n",
    "The `hf` output format makes it easier to inspect and manipulate with tools like `pandas` and `datasets`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python .gorilla/raft/format.py \\\n",
    "    --input \"$RAFT_ARROW_FILE\" \\\n",
    "    --output \"$DATASET_PATH_HF\" \\\n",
    "    --output-format hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preview the full HF JSONL dataset\n",
    "\n",
    "This cell imports `pandas`, reads the full synthetic dataset from `$DATASET_PATH_HF` into a DataFrame, and shows the first five rows.  \n",
    "It provides a quick sanity check that RAFT successfully generated instructions, questions, answers, and contexts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the synthetic dataset generated in the HF JSONL stage\n",
    "import pandas as pd\n",
    "\n",
    "hf_full_df = pd.read_json(dataset_path_hf, lines=True)\n",
    "hf_full_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render a formatted sample from the HF dataset\n",
    "\n",
    "This cell selects an example from `hf_full_df` and:\n",
    "- Cleans up `<DOCUMENT>` and similar tags for Markdown display,\n",
    "- Builds a formatted view showing the **oracle context**, **question**, and **chain-of-thought answer**,\n",
    "- Displays it neatly with `IPython.display.Markdown`.\n",
    "\n",
    "The **oracle context** shows the exact text the model used to generate the question.  \n",
    "The **question** tests the model’s understanding of that context.  \n",
    "The **chain-of-thought answer** reveals the reasoning path, not just the final answer, helping verify that the generated data teaches logical reasoning instead of recall from memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display a random sample from the HF dataset to inspect structure and content\n",
    "from IPython.display import display, Markdown\n",
    "from random import randint\n",
    "\n",
    "sample_idx = 2\n",
    "sample = hf_full_df.iloc[sample_idx]\n",
    "\n",
    "instruction_md = sample.instruction.replace(\"<DOCUMENT>\", \"`<DOCUMENT>`\").replace(\"</DOCUMENT>\", \"`</DOCUMENT>`\")\n",
    "oracle_context_md = sample.oracle_context.replace(\"<DOCUMENT>\", \"`<DOCUMENT>`\").replace(\"</DOCUMENT>\", \"`</DOCUMENT>`\")\n",
    "sample_answer_md = sample.cot_answer.replace(\"<ANSWER>\", \"`<ANSWER>`\").replace(\"##begin_quote##\", \"`##begin_quote##`\").replace(\"##end_quote##\", \"`##end_quote##`\")\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "## Oracle Context\n",
    "{oracle_context_md}\n",
    "\n",
    "## Question\n",
    "{sample.question}\n",
    "\n",
    "## CoT Answer\n",
    "{sample_answer_md}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split HF dataset into train/valid/eval JSONL files\n",
    "\n",
    "This cell:\n",
    "- Computes the index cut points for train and validation splits using the configured ratios,\n",
    "- Logs how many samples land in each split and where they will be saved,\n",
    "- Uses `numpy.split` to partition `hf_full_df` into train, validation, and eval DataFrames,\n",
    "- Writes each split out as line-delimited JSONL files at the configured paths.\n",
    "\n",
    "These HF JSONL splits are the basis for later finetuning and evaluation datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the HF JSONL dataset into train/valid/eval splits and write them to disk\n",
    "import numpy as np\n",
    "\n",
    "samples_count = len(hf_full_df)\n",
    "train_cut = int(finetuning_train_split * samples_count)\n",
    "valid_cut = int((finetuning_train_split + finetuning_valid_split) * samples_count)\n",
    "splits = [train_cut, valid_cut]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "Splitting HF dataset\n",
    "--------------------\n",
    "Total samples : {samples_count}\n",
    "Train split   : 0 -> {train_cut}        -> {dataset_path_hf_train}\n",
    "Valid split   : {train_cut} -> {valid_cut} -> {dataset_path_hf_valid}\n",
    "Eval split    : {valid_cut} -> {samples_count} -> {dataset_path_hf_eval}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "hf_train_df, hf_valid_df, hf_eval_df = np.split(hf_full_df, splits)\n",
    "\n",
    "hf_train_df.to_json(dataset_path_hf_train, orient=\"records\", lines=True)\n",
    "hf_valid_df.to_json(dataset_path_hf_valid, orient=\"records\", lines=True)\n",
    "hf_eval_df.to_json(dataset_path_hf_eval, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert HF train split into RAFT-style finetuning dataset\n",
    "\n",
    "This cell calls `format.py` again to:\n",
    "- Take the HF train JSONL (`$DATASET_PATH_HF_TRAIN`) as input,\n",
    "- Produce a RAFT-style finetuning JSONL (`$DATASET_PATH_FT_TRAIN`),\n",
    "- Map the question/answer fields into a standard schema where `text` is the prompt and `ground_truth` is the completion.\n",
    "\n",
    "The resulting file is directly usable as the finetuning dataset for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .gorilla/raft/format.py \\\n",
    "    --input \"$DATASET_PATH_HF_TRAIN\" \\\n",
    "    --input-type jsonl \\\n",
    "    --output \"$DATASET_PATH_FT_TRAIN\" \\\n",
    "    --output-format \"$FORMAT\" \\\n",
    "    --output-completion-prompt-column text \\\n",
    "    --output-completion-completion-column ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert HF validation split into RAFT-style finetuning dataset\n",
    "\n",
    "This cell performs the same RAFT `format.py` transformation as above, but for the validation split:\n",
    "- Input: `$DATASET_PATH_HF_VALID` (HF JSONL),\n",
    "- Output: `$DATASET_PATH_FT_VALID` (RAFT-style JSONL),\n",
    "- Uses the same `text` / `ground_truth` mapping.\n",
    "\n",
    "This RAFT-style validation set will be used to gauge finetuning performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python .gorilla/raft/format.py \\\n",
    "    --input \"$DATASET_PATH_HF_VALID\" \\\n",
    "    --input-type jsonl \\\n",
    "    --output \"$DATASET_PATH_FT_VALID\" \\\n",
    "    --output-format \"$FORMAT\" \\\n",
    "    --output-completion-prompt-column text \\\n",
    "    --output-completion-completion-column ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect finetuning and evaluation datasets\n",
    "\n",
    "This cell:\n",
    "- Loads the RAFT-style finetuning validation dataset from `dataset_path_ft_valid` and shows its first two rows,\n",
    "- Loads the HF eval JSONL (`dataset_path_hf_eval`) and shows its first two rows.\n",
    "\n",
    "It provides a final verification that both the finetuning and evaluation splits are correctly formatted and ready for the next notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect finetuning and eval splits\n",
    "dataset_path_ft_valid_df = pd.read_json(dataset_path_ft_valid, lines=True)\n",
    "dataset_path_ft_valid_df.head(2)\n",
    "\n",
    "pd.read_json(dataset_path_hf_eval, lines=True).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
